#!/usr/bin/python
# -*- encoding: utf-8 -*-
import os, shutil, atexit, tempfile, logging
import simstring
import db, dbutil, doiutil, nameutil, util
import conf.dedupconf as dedupconf

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('deduplicate')

def merge(revisions):
    """ Junta uma lista de revisões, indicando que são duplicatas """
    if len(revisions) < 2:
        # Juntar menos de 2 revisões é uma operação nula
        return
    # Por padrão, define a primeira revisão da lista como a principal.
    # A tarefa de escolher a melhor revisão é delegada para o próximo script.
    mainId = revisions[0].id
    # Mantém a revisão do item principal existente, se houver
    for rev in revisions:
        if rev.duplicate_of_id:
            # Escolhe a última revisão do item. Caso o item não tenha sido
            # modificado no CV Lattes desde a última sincronização, essa
            # revisão é a mesma que a rev.duplicate_of_id. Caso o item principal
            # tenha sido modificado, ainda assim é seguro utilizar a última revisão
            # do mesmo, pois esta será varrida pelo yieldNotYetSyncedRevisions
            mainId = rev.duplicate_of.item.last_revision.id
            break
    # Modifica o campo de todas as revisões, tirando a principal
    for rev in revisions:
        assert(isinstance(rev, db.Revision))  # evita uso acidental de LastRevision, que é readonly
        if rev.id != mainId:
            db.session.add(rev)
            rev.duplicate_of_id = mainId
    db.session.commit()

def deduplicateDoi():
    meta_uri0 = db.LastRevision.meta[('dc','identifier','uri',0,'value')].astext

    q = db.session.query(db.LastRevision.item_id, meta_uri0)\
                  .join(db.LastRevision.item)\
                  .filter(db.LastRevision.duplicate_of_id.is_(None))

    g = dbutil.yieldNotYetSyncedRevisions(q, batch_size=16384, id_from_row=lambda row:row[0])
    for item_id, uri in g:
        doi = doiutil.filter(uri)
        if doi:
            # Busca duplicatas por DOI idêntico
            duplicates = db.session.query(db.Revision)\
                                   .join(db.Revision.last_revision)\
                                   .filter(db.func.lower(meta_uri0) == doi.lower()).all()
            if len(duplicates) >= 2:
                logger.info('Encontradas %d duplicatas do item.id=%r pelo DOI %r',
                            len(duplicates), item_id, doi)
                merge(duplicates)

    db.session.refresh_materialized_view(db.LastRevision)

def deduplicateTitle():
    simInq = SimilarTitleInquirer()
    # TODO: Lembrar de tratar os seguintes casos:
    #   - Se duplicatas encontradas possuírem DOIs diferentes, utilizar apenas o com melhor ranking
    #   - Não considerar duplicatas se estiverem no mesmo CV

class SimilarTitleInquirer(object):
    _instance = None  # Singleton
    def __new__(klass, *args, **kwargs):
        if not klass._instance:
            klass._instance = super(SimilarTitleInquirer, klass).__new__(klass, *args, **kwargs)
            klass._instance._populateTitleTempTable()
            klass._instance._populateSimStringDB()
        return klass._instance

    def __del__(self):
        self.ssdb.close()

    def query(self, title):
        """
        Procura títulos similares a `title`

        Retorna uma lista rankeada no formato:
        [(distancia1, [revisao1, revisao2, ..., revisaoN]),
         (distancia2, [revisaoN+1, revisaoN+2, ..., revisaoM]),
         ...]
        """
        title = util.norm(title).encode('ascii')
        similarTitles = set(self.ssdb.retrieve(title))
        similarTitles.add(title)
        # Rankeia os títulos similares encontrados de acordo com a distância Levenshtein
        rankedTitles = sorted([(nameutil.levenshtein(title, s), s) for s in similarTitles])
        # Obtém as revisões correspondentes a cada um desses títulos
        # Note que, no caso de as duplicatas possuírem título normalizado exatamente igual,
        # é possível existir mais de uma revisão com o mesmo título
        results = [(dist, db.session.query(db.LastRevision)
                                    .join((db.RevNormTitle, db.RevNormTitle.id == db.LastRevision.id))
                                    .filter(db.RevNormTitle.title == title).all())
                   for (dist, title) in rankedTitles]
        # Retorna apenas resultados não-vazios
        return [(dist, revisions) for (dist, revisions) in results
                if len(revisions) > 0]

    def _populateTitleTempTable(self):
        logger.info('Indexando versões exatas dos títulos normalizados')

        db.create_temp_table(db.RevNormTitle)
        meta_title = db.LastRevision.meta[('dc','title','""',0,'value')].astext

        q = db.session.query(db.LastRevision.item_id, meta_title)\
                      .join(db.LastRevision.item)\
                      .filter(meta_title.isnot(None))

        batch_size = 16384
        i = 0
        g = db.yield_batches(q, db.LastRevision.item_id, batch_size=batch_size,
                             id_from_row=lambda row:row[0])
        for item_id, title in g:
            db.session.add(db.RevNormTitle(id = item_id, title = util.norm(title)))
            i += 1
            if i % batch_size == 0:
                db.session.commit()
                logger.info('Indexados %r itens', i)
        db.session.commit()

    def _populateSimStringDB(self):
        logger.info('Criando índice de busca de similares com o simstring')

        tempdir = tempfile.mkdtemp()
        atexit.register(lambda: shutil.rmtree(tempdir))
        filename = os.path.join(tempdir, 'title.db')

        ssdb = simstring.writer(filename)
        g = db.yield_batches(db.session.query(db.RevNormTitle),
                             db.RevNormTitle.id,
                             batch_size=16384)
        for result in g:
            ssdb.insert(result.title.encode('ascii'))
        ssdb.close()

        self.ssdb = simstring.reader(filename)
        self.ssdb.measure = dedupconf.titleMeasure
        self.ssdb.threshold = dedupconf.titleThreshold

def main():
    deduplicateDoi()
    deduplicateTitle()

if __name__ == '__main__':
    main()

